# ChatPDF ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [è¯¦ç»†é…ç½®](#è¯¦ç»†é…ç½®)
3. [åŠŸèƒ½ä½¿ç”¨](#åŠŸèƒ½ä½¿ç”¨)
4. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
5. [è¿›é˜¶ä½¿ç”¨](#è¿›é˜¶ä½¿ç”¨)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

**åç«¯å¯åŠ¨ï¼š**
```bash
chmod +x start_backend.sh
./start_backend.sh
```

**å‰ç«¯å¯åŠ¨ï¼š**
```bash
cd chatpdf-frontend
npm install
npm start
```

### æ–¹æ³•äºŒï¼šæ‰‹åŠ¨å¯åŠ¨

**1. å¯åŠ¨åç«¯**
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¯åŠ¨æœåŠ¡
python chatpdf_backend.py
```

**2. å¯åŠ¨å‰ç«¯**
```bash
# åˆ›å»ºReacté¡¹ç›®
npx create-react-app chatpdf-frontend
cd chatpdf-frontend

# å®‰è£…ä¾èµ–
npm install lucide-react
npm install -D tailwindcss postcss autoprefixer

# é…ç½®Tailwind
npx tailwindcss init

# å¤åˆ¶ç»„ä»¶æ–‡ä»¶
# å°†ChatPDF.jsxå¤åˆ¶åˆ°src/components/

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm start
```

### æ–¹æ³•ä¸‰ï¼šä½¿ç”¨Docker

```bash
# æ„å»ºå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

---

## âš™ï¸ è¯¦ç»†é…ç½®

### 1. APIé…ç½®

#### OpenAIé…ç½®
```
APIæä¾›å•†: openai
æ¨¡å‹: gpt-3.5-turbo (ç»æµ) æˆ– gpt-4 (é«˜è´¨é‡)
API Key: ä» https://platform.openai.com/api-keys è·å–
```

#### Anthropic Claudeé…ç½®
```
APIæä¾›å•†: anthropic
æ¨¡å‹: claude-3-sonnet-20240229 (æ¨è) æˆ– claude-3-opus-20240229
API Key: ä» https://console.anthropic.com/ è·å–
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```env
# å¯é€‰ï¼šè®¾ç½®é»˜è®¤é…ç½®
DEFAULT_API_PROVIDER=openai
DEFAULT_MODEL=gpt-3.5-turbo
MAX_FILE_SIZE=10485760
```

### 3. é«˜çº§é…ç½®

**ä¿®æ”¹åç«¯ç«¯å£ï¼š**
```python
# åœ¨ chatpdf_backend.py åº•éƒ¨ä¿®æ”¹
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)  # æ”¹ä¸º8080
```

**ä¿®æ”¹å‰ç«¯APIåœ°å€ï¼š**
```javascript
// åœ¨ ChatPDF.jsx ä¸­ä¿®æ”¹
const API_BASE_URL = 'http://your-backend-url:8000';
```

---

## ğŸ“– åŠŸèƒ½ä½¿ç”¨

### 1. ä¸Šä¼ PDFæ–‡æ¡£

**æ­¥éª¤ï¼š**
1. æ‰“å¼€åº”ç”¨ `http://localhost:3000`
2. ç‚¹å‡»"é€‰æ‹©PDFæ–‡ä»¶"æŒ‰é’®
3. é€‰æ‹©è¦åˆ†æçš„PDFæ–‡æ¡£
4. ç­‰å¾…ä¸Šä¼ å®Œæˆ

**æ”¯æŒçš„æ–‡æ¡£ï¼š**
- âœ… æ–‡æœ¬å‹PDFï¼ˆå¯å¤åˆ¶æ–‡æœ¬ï¼‰
- âŒ æ‰«æå‹PDFï¼ˆéœ€è¦OCRï¼Œå½“å‰ç‰ˆæœ¬ä¸æ”¯æŒï¼‰
- ğŸ“ å»ºè®®å¤§å°ï¼š< 10MB
- ğŸ“„ å»ºè®®é¡µæ•°ï¼š< 100é¡µ

### 2. æŸ¥çœ‹æ–‡æ¡£æ‘˜è¦

**è‡ªåŠ¨ç”Ÿæˆï¼š**
- æ–‡æ¡£ä¸Šä¼ åè‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
- æ˜¾ç¤ºæ–‡æ¡£æ ¸å¿ƒè¦ç‚¹
- æä¾›5ä¸ªå»ºè®®é—®é¢˜

**æ‰‹åŠ¨åˆ·æ–°ï¼š**
```javascript
// å¯ä»¥åœ¨ä»£ç ä¸­æ·»åŠ åˆ·æ–°æŒ‰é’®
<button onClick={() => generateSummary(docId)}>
  é‡æ–°ç”Ÿæˆæ‘˜è¦
</button>
```

### 3. ä¸æ–‡æ¡£å¯¹è¯

**æé—®æŠ€å·§ï¼š**

**âœ… å¥½çš„é—®é¢˜ï¼š**
- "è¿™ç¯‡æ–‡æ¡£çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
- "æ–‡æ¡£ä¸­æåˆ°äº†å“ªäº›å…³é”®æ•°æ®ï¼Ÿ"
- "è¯·è§£é‡Šç¬¬3é¡µçš„å›¾è¡¨å«ä¹‰"
- "ä½œè€…çš„ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ"

**âŒ é¿å…çš„é—®é¢˜ï¼š**
- "ä½ è§‰å¾—è¿™ä¸ªè§‚ç‚¹å¯¹å—ï¼Ÿ"ï¼ˆAIåªåŸºäºæ–‡æ¡£å†…å®¹ï¼‰
- "å¸®æˆ‘å†™ä¸€ç¯‡æ–°æ–‡ç« "ï¼ˆè¶…å‡ºæ–‡æ¡£èŒƒå›´ï¼‰

**æé—®ç¤ºä¾‹ï¼š**

```
ğŸ“„ ç ”ç©¶è®ºæ–‡åˆ†æï¼š
- "è¿™é¡¹ç ”ç©¶çš„æ–¹æ³•è®ºæ˜¯ä»€ä¹ˆï¼Ÿ"
- "å®éªŒç»“æœæ”¯æŒå‡è®¾å—ï¼Ÿ"
- "æ–‡ç« çš„å±€é™æ€§åœ¨å“ªé‡Œï¼Ÿ"

ğŸ“Š å•†ä¸šæŠ¥å‘Šåˆ†æï¼š
- "æœ¬å­£åº¦çš„ä¸»è¦è´¢åŠ¡æŒ‡æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ"
- "æŠ¥å‘Šä¸­æåˆ°äº†å“ªäº›é£é™©ï¼Ÿ"
- "æœªæ¥çš„å¢é•¿ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ"

ğŸ“– æŠ€æœ¯æ–‡æ¡£åˆ†æï¼š
- "å¦‚ä½•é…ç½®è¿™ä¸ªåŠŸèƒ½ï¼Ÿ"
- "æœ‰å“ªäº›APIæ¥å£ï¼Ÿ"
- "æ–‡æ¡£ä¸­çš„ç¤ºä¾‹ä»£ç æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"
```

### 4. ä½¿ç”¨å»ºè®®é—®é¢˜

**å¿«é€Ÿæé—®ï¼š**
1. æŸ¥çœ‹æ‘˜è¦ä¸‹æ–¹çš„å»ºè®®é—®é¢˜
2. ç‚¹å‡»ä»»æ„é—®é¢˜
3. é—®é¢˜è‡ªåŠ¨å¡«å……åˆ°è¾“å…¥æ¡†
4. å‘é€æˆ–ä¿®æ”¹åå‘é€

---

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸Šä¼ å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
1. PDFæ–‡ä»¶è¿‡å¤§ï¼ˆ>10MBï¼‰
2. PDFæ–‡ä»¶æŸå
3. ç½‘ç»œè¿æ¥é—®é¢˜

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥åç«¯æ˜¯å¦è¿è¡Œ
curl http://localhost:8000/health

# æ£€æŸ¥æ–‡ä»¶å¤§å°
ls -lh your_file.pdf

# å‹ç¼©PDF
# ä½¿ç”¨åœ¨çº¿å·¥å…·æˆ–PDFå‹ç¼©è½¯ä»¶
```

### Q2: AIå›ç­”ä¸å‡†ç¡®ï¼Ÿ

**æ”¹è¿›æ–¹æ³•ï¼š**
1. **ä½¿ç”¨æ›´å¼ºæ¨¡å‹**ï¼šæ”¹ç”¨GPT-4æˆ–Claude-3-Opus
2. **ä¼˜åŒ–é—®é¢˜**ï¼šæé—®æ›´å…·ä½“æ˜ç¡®
3. **æ£€æŸ¥æ–‡æ¡£**ï¼šç¡®ä¿PDFæ–‡æœ¬æå–æ­£ç¡®
4. **åˆ†æ®µæé—®**ï¼šå°†å¤æ‚é—®é¢˜æ‹†åˆ†

### Q3: APIè°ƒç”¨å¤±è´¥ï¼Ÿ

**æ£€æŸ¥æ¸…å•ï¼š**
```bash
âœ… API Keyæ˜¯å¦æ­£ç¡®
âœ… API Keyæ˜¯å¦æœ‰ä½™é¢
âœ… ç½‘ç»œæ˜¯å¦èƒ½è®¿é—®API
âœ… æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®
```

**æµ‹è¯•APIè¿æ¥ï¼š**
```bash
# OpenAIæµ‹è¯•
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer YOUR_API_KEY"

# Anthropicæµ‹è¯•
curl https://api.anthropic.com/v1/messages \
  -H "x-api-key: YOUR_API_KEY" \
  -H "anthropic-version: 2023-06-01"
```

### Q4: æ–‡æ¡£å†…å®¹æ˜¾ç¤ºä¹±ç ï¼Ÿ

**åŸå› ï¼š**
- PDFä½¿ç”¨ç‰¹æ®Šç¼–ç 
- åŒ…å«éæ–‡æœ¬å…ƒç´ ï¼ˆå›¾ç‰‡ã€å…¬å¼ï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ä½¿ç”¨pdfplumberæ›¿ä»£PyPDF2
pip install pdfplumber

# åœ¨backendä¸­ä¿®æ”¹å¯¼å…¥
import pdfplumber
# ç„¶åä¿®æ”¹extract_text_from_pdfå‡½æ•°
```

### Q5: éƒ¨ç½²åˆ°æœåŠ¡å™¨åCORSé”™è¯¯ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# åœ¨chatpdf_backend.pyä¸­ä¿®æ”¹CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://your-domain.com",  # æ·»åŠ ä½ çš„åŸŸå
        "https://your-domain.com"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

## ğŸ“ è¿›é˜¶ä½¿ç”¨

### 1. æ·»åŠ å‘é‡æ•°æ®åº“ï¼ˆæå‡å‡†ç¡®æ€§ï¼‰

**ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ**
- æ–‡æ¡£å¤ªé•¿ï¼Œè¶…å‡ºtokené™åˆ¶
- æé«˜ä¿¡æ¯æ£€ç´¢å‡†ç¡®æ€§
- æ”¯æŒè¯­ä¹‰æœç´¢

**å®ç°æ–¹æ¡ˆï¼š**

```bash
# å®‰è£…ä¾èµ–
pip install chromadb sentence-transformers
```

```python
# é›†æˆChromaDB
import chromadb
from sentence_transformers import SentenceTransformer

# åˆå§‹åŒ–
client = chromadb.Client()
model = SentenceTransformer('all-MiniLM-L6-v2')

# å­˜å‚¨æ–‡æ¡£å‘é‡
def store_document_embeddings(doc_id, pages):
    collection = client.create_collection(doc_id)
    
    for page in pages:
        embedding = model.encode(page['content'])
        collection.add(
            embeddings=[embedding.tolist()],
            documents=[page['content']],
            metadatas=[{"page": page['page']}],
            ids=[f"page_{page['page']}"]
        )

# æ£€ç´¢ç›¸å…³å†…å®¹
def search_relevant_content(doc_id, question, n_results=3):
    collection = client.get_collection(doc_id)
    question_embedding = model.encode(question)
    
    results = collection.query(
        query_embeddings=[question_embedding.tolist()],
        n_results=n_results
    )
    
    return results['documents'][0]
```

### 2. æ·»åŠ OCRæ”¯æŒï¼ˆæ‰«æç‰ˆPDFï¼‰

```bash
# å®‰è£…Tesseract OCR
# Ubuntu/Debian
sudo apt-get install tesseract-ocr

# macOS
brew install tesseract

# å®‰è£…Pythonåº“
pip install pytesseract pdf2image
```

```python
# æ·»åŠ OCRåŠŸèƒ½
from pdf2image import convert_from_path
import pytesseract

def extract_text_with_ocr(pdf_path):
    images = convert_from_path(pdf_path)
    text = ""
    
    for i, image in enumerate(images):
        text += f"\n--- Page {i+1} ---\n"
        text += pytesseract.image_to_string(image, lang='chi_sim+eng')
    
    return text
```

### 3. æ·»åŠ ç”¨æˆ·è®¤è¯ç³»ç»Ÿ

```bash
pip install python-jose[cryptography] passlib[bcrypt]
```

```python
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from passlib.context import CryptContext
from jose import JWTError, jwt

# é…ç½®
SECRET_KEY = "your-secret-key"
ALGORITHM = "HS256"
pwd_context = CryptContext(schemes=["bcrypt"])
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

# åˆ›å»ºtoken
def create_access_token(data: dict):
    to_encode = data.copy()
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

# éªŒè¯token
async def get_current_user(token: str = Depends(oauth2_scheme)):
    credentials_exception = HTTPException(status_code=401)
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    return username
```

### 4. æ•°æ®åº“æŒä¹…åŒ–

```bash
pip install sqlalchemy alembic
```

```python
from sqlalchemy import create_engine, Column, String, Text, DateTime
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()

class Document(Base):
    __tablename__ = "documents"
    
    id = Column(String, primary_key=True)
    filename = Column(String)
    content = Column(Text)
    upload_time = Column(DateTime)
    user_id = Column(String)

# åˆ›å»ºæ•°æ®åº“
engine = create_engine('sqlite:///chatpdf.db')
Base.metadata.create_all(engine)
```

### 5. æ·»åŠ æ–‡æ¡£ç¿»è¯‘åŠŸèƒ½

```python
async def translate_document(doc_id: str, target_lang: str, api_key: str):
    """ç¿»è¯‘æ•´ä¸ªæ–‡æ¡£"""
    doc = documents_store[doc_id]
    
    messages = [
        {
            "role": "system",
            "content": f"è¯·å°†ä»¥ä¸‹æ–‡æ¡£ç¿»è¯‘æˆ{target_lang}ï¼Œä¿æŒåŸæœ‰æ ¼å¼å’Œç»“æ„ã€‚"
        },
        {
            "role": "user",
            "content": doc["data"]["full_text"][:8000]
        }
    ]
    
    response = await call_ai_api(messages, api_key, model, provider)
    return response["choices"][0]["message"]["content"]
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import hashlib

# ç¼“å­˜æ‘˜è¦ç»“æœ
summary_cache = {}

def get_cache_key(doc_id, model):
    return hashlib.md5(f"{doc_id}:{model}".encode()).hexdigest()

async def generate_summary_cached(request):
    cache_key = get_cache_key(request.doc_id, request.model)
    
    if cache_key in summary_cache:
        return summary_cache[cache_key]
    
    result = await generate_summary(request)
    summary_cache[cache_key] = result
    return result
```

### 2. å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—

```bash
pip install celery redis
```

```python
from celery import Celery

celery_app = Celery('chatpdf', broker='redis://localhost:6379')

@celery_app.task
def generate_summary_task(doc_id, api_key, model):
    # å¼‚æ­¥å¤„ç†æ‘˜è¦ç”Ÿæˆ
    pass
```

### 3. æ–‡æ¡£åˆ†å—å¤„ç†

```python
def chunk_text(text, chunk_size=2000, overlap=200):
    """å°†æ–‡æœ¬åˆ†å—"""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
    
    return chunks
```

---

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

1. **æ°¸è¿œä¸è¦æš´éœ²API Key**
2. **ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯**
3. **æ·»åŠ è¯·æ±‚é¢‘ç‡é™åˆ¶**
4. **éªŒè¯ä¸Šä¼ æ–‡ä»¶ç±»å‹å’Œå¤§å°**
5. **ä½¿ç”¨HTTPSåŠ å¯†ä¼ è¾“**
6. **å®šæœŸæ›´æ–°ä¾èµ–åŒ…**
7. **æ·»åŠ æ—¥å¿—è®°å½•å’Œç›‘æ§**

---

## ğŸ“ è·å–å¸®åŠ©

- ğŸ“– æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼š`README.md`
- ğŸ› æŠ¥å‘Šé—®é¢˜ï¼šæäº¤GitHub Issue
- ğŸ’¬ æŠ€æœ¯è®¨è®ºï¼šåŠ å…¥ç¤¾åŒº

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜éšæ—¶æŸ¥é˜…æœ¬æŒ‡å—ã€‚** ğŸ‰
